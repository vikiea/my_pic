# 数据库与缓存学习
## MySQL，Oracle，SQL Server的区别
### 应用场景方面
1. **Oracle**。Oracle的应用，主要在传统行业的数据化业务中，比如：银行、金融这样的对可用性、健壮性、安全性、实时性要求极高的业务；零售、物流这样对海量数据存储分析要求很高的业务。此外，高新制造业如芯片厂也基本都离不开Oracle；电商也有很多使用者，如京东（正在投奔Oracle）、阿里巴巴（计划去Oracle化）。而且由于Oracle对复杂计算、统计分析的强大支持，在互联网数据分析、数据挖掘方面的应用也越来越多。
2. **MySQL**。MySQL基本是生于互联网，长于互联网。其应用实例也大都集中于互联网方向，MySQL的高并发存取能力并不比大型数据库差，同时价格便宜，安装使用简便快捷，深受广大互联网公司的喜爱。并且由于MySQL的开源特性，针对一些对数据库有特别要求的应用，可以通过修改代码来实现定向优化，例如SNS、LBS等互联网业务。
3. **MS SQL Server**。windows生态系统的产品，好处坏处都很分明。好处就是，高度集成化，微软也提供了整套的软件方案，基本上一套win系统装下来就齐活了。因此，不那么缺钱，但很缺IT人才的中小企业，会偏爱 MS SQL Server 。例如，自建ERP系统、商业智能、垂直领域零售商、餐饮、事业单位等等。

### 架构方面
1. **Oracle**： 数据文件包括：控制文件、数据文件、重做日志文件、参数文件、归档文件、密码文件。这是**根据文件功能行进行划分，并且所有文件都是二进制编码后的文件**，对数据库算法效率有极大的提高。由于Oracle文件管理的统一性，就可以**对SQL执行过程中的解析和优化，指定统一的标准**：**RBO（基于规则的优化器）**、**CBO（基于成本的优化器）**通过优化器的选择，以及**无敌的HINT规则**，给与了SQL优化极大的自由，对CPU、内存、IO资源进行方方面面的优化。
2. **MySQL**：最大的一个特色，就是**自由选择存储引擎**。每个表都是一个文件，都可以选择合适的存储引擎。常见的引擎有 InnoDB、 MyISAM、 NDBCluster等。但由于这种开放插件式的存储引擎，比如要求**数据库与引擎之间的松耦合关系，从而导致文件的一致性大大降低。**在SQL执行优化方面，也就有着一些不可避免的瓶颈。在**多表关联、子查询优化、统计函数等方面是软肋，而且只支持极简单的HINT**。
3. **SQL Server** ：**数据架构基本是纵向划分**，分为：**Protocol Layer（协议层）， Relational Engine（关系引擎）， Storage Engine（存储引擎）， SQLOS**。SQL执行过程就是**逐层解析的过程**，其中Relational Engine中的优化器，是**基于成本的（CBO）**，其工作过程跟Oracle是非常相似的。在成本之上也是**支持很丰富的HINT**，包括：连接提示、查询提示、表提示。

### 功能方面

| 功能 | MySQL | Oracle |
| --- | --- | --- |
| 并发性 |  mysql以表级锁为主，对资源锁定的粒度很大，<br>如果一个session对一个表加锁时间过长，<br>会让其他session无法更新此表中的数据。<br>虽然InnoDB引擎的表可以用行级锁，<br>但这个行级锁的机制依赖于表的索引，<br>如果表没有索引，或者sql语句没有使用索引，<br>那么仍然使用表级锁。|oracle使用行级锁，对资源锁定的粒度要小很多，<br>只是锁定sql需要的资源，并且加锁是在数据库中的数据行上，<br>不依赖与索引。所以oracle对并发性的支持要好很多。 |
| 一致性 | mysql没有类似oracle的构造多版本数据块的机制，<br>一个session读取数据时，其他session不能更改数据，<br>但可以在表最后插入数据。session更新数据时，<br>要加上排它锁，其他session无法访问数据。| oracle支持serializable的隔离级别，<br>可以实现最高级别的读一致性。每个session<br>提交后其他session才能看到提交的更改。<br>oracle通过在undo表空间中构造多版本数据块<br>来实现读一致性，每个session查询时，<br>如果对应的数据块发生变化，oracle会在<br>undo表空间中为这个session构造它查询时的旧的数据块。|
| 事务 | mysql在innodb存储引擎的行级锁的情况下才支持事务。| oracle很早就完全支持事务。 |
| 数据持久性 |默认提交sql语句，但如果更新过程中出现<br>db或主机重启的问题，也许会丢失数据。 | oracle保证提交的数据均可恢复，因为oracle<br>把提交的sql操作先写入了在线联机日志文件中，<br>保持到了磁盘上，如果出现数据库或主机异常重启，<br>重启后oracle可以考联机在线日志恢复<br>客户提交的数据。 |
| 提交方式 | mysql默认是自动提交。| oracle默认不自动提交，需要用户手动提交。|
| 逻辑备份 | mysql逻辑备份时要锁定数据，才能保证<br>备份的数据是一致的，影响业务正常的dml使用。 | oracle逻辑备份时不锁定数据，且备份的数据是一致的。 |
| 热备份 | myisam的引擎，<br>用mysql自带的mysqlhotcopy热备时，<br>需要给表加读锁，影响dml操作。<br>innodb的引擎，<br>它会备份innodb的表和索引，但是不会备份.frm文件。<br>用ibbackup备份时，<br>会有一个日志文件记录备份期间的数据变化，<br>因此可以不用锁表，不影响其他用户使用数据库。<br>但此工具是收费的。innobackup是结合ibbackup使用的一个脚本，<br>他会协助对.frm文件的备份。 | oracle有成熟的热备工具rman，热备时，<br>不影响用户使用数据库。即使备份的数据库不一致，<br>也可以在恢复时通过归档日志和联机重做日志进行一致的回复。 |
| sql语句的扩展和灵活性 | mysql对sql语句有很多非常实用而方便的扩展，<br>比如limit功能，insert可以一次插入多行数据，<br>select某些管理数据可以不加from。| oracle在这方面感觉更加稳重传统一些。 |
| 复制 | 复制服务器配置简单，但主库出问题时，<br>丛库有可能丢失一定的数据。且需要手工切换丛库到主库。 | 既有推或拉式的传统数据复制，也有dataguard的双机或多机<br>容灾机制，主库出现问题时，可以<br>自动切换备库到主库，但配置管理较复杂。|
| 性能诊断 | mysql的诊断调优方法较少，主要有慢查询日志。 | oracle有各种成熟的性能诊断调优工具，<br>能实现很多自动分析、诊断功能。比如awr、addm、<br>sqltrace、tkproof等 |
| 权限与安全 | mysql的用户与主机有关，感觉没有什么意义，<br>另外更容易被仿冒主机及ip有可乘之机。 | 权限与安全概念比较传统，中规中矩。|
| 分区表和分区索引 | mysql的分区表还不太成熟稳定。 | oracle的分区表和分区索引功能很成熟，可以提高用户访问db的体验 |
| 管理工具 | mysql管理工具较少，在linux下的管理工具<br>的安装有时要安装额外的包（phpmyadmin， etc)，有一定复杂性。| oracle有多种成熟的命令行、图形界面、<br>web管理工具，还有很多第三方的管理工具，管理极其方便高效 |

## 数据库应用优化
### 基本语句优化原则
1. 尽量避免在列上运算，会使索引失效
2. 尽量以小结果集驱动大结果集
3. 尽量避免LIKE模糊查询
4. 仅列出所需查询字段，节省内存
5. 使用批量插入进行交互
6. limit较大时用between，或者先定位id,再limit，如id>30000000,limit10
7. 不使用随机函数rand获取多条随机记录（可先用PHP产生随机数，再查询）
8. 避免使用NULL
9. 当只要一行数据时使用LIMIT 1
10. 使用`count(*)`而不是`count(id)`（`count(*)`会走索引，而`count(id)`是全表扫描）
11. 不做无谓的排序操作，尽量在索引中完成排序
12. 为经常使用的搜索字段建索引
13. 不要在数据很大的字段上建立索引
14. 使用连接（JOIN）来代替子查询(Sub-Queries)
15. 尽量在多个条件的时候，把会提取尽量少数据量的条件放在前面，减少后一个where条件的查询时间。

### MySQL数据类型选择
#### 数值类型

| 类型 | 大小 | 范围（有符号型） | 范围（无符号型） | 用途 |
| --- | --- | --- | --- | --- |
| TINYINT | 1Byte | (-128,127),即$(-2^7,2^7)$ | (0,255),$(0,2^8)$ | 小整数值 |
| SMALLINT | 2Bytes | $(-2^{15},2^{15})$ | $(0,2^{16})$ | 大整数值 |
| MEDIUMINT | 3Bytes | $(-2^{23},2^{23})$ | $(0,2^{24})$ | 大整数值 |
| INT或INTEGER | 4Bytes | $(-2^{31},2^{31})$ | $(0,2^{32})$ | 大整数值 |
| BIGINT | 8Bytes | $(-2^{63},2^{63})$ | $(0,2^{64})$ | 极大整数值 |
| FLOAT | 4Bytes |  |  | 单精度浮点数 |
| DOUBLE | 8Bytes |  | | 双精度浮点数 |
| DECIMAL | 对DECIMAL(M,D),如果M>D,为M+2,否则为D+2 | 依赖于M和D的值 | 依赖于M和D的值 | 精确 小数值 |

##### 优化建议
1. 如果整形数据没有负数，如ID号，建议指定为UNSIGNED无符号类型，容量可以扩大一倍。
2. 建议使用TINYINT代替ENUM、BITENUM、SET。
3. 避免使用整数的显示宽度，也就是说，不要用INT(10)类似的方法指定字段显示宽度，直接用INT。关于INT显示宽度。
4. 用INT UNSIGNED来存储IPv4地址，用VARBINARY来存储IPv6地址，当然存储之前需要用PHP函数转换。
5. DECIMAL最适合保存准确度要求高，而且用于计算的数据，比如价格。但是在使用DECIMAL类型的时候，注意长度设置。
6. 建议使用整形类型来运算和存储实数，方法是，实数乘以相应的倍数后再操作。
7. 整数通常是最佳的数据类型，因为它速度快，并且能使用AUTO_INCREMENT。

#### 日期和时间
| 类型 | 大小 | 范围 | 格式 | 用途 |
| --- | --- | --- | --- | --- |
| DATE |    3Bytes  | 1000-01-01  到 9999-12-31 | YYYY-MM-DD | 日期值 |
| TIME |    3Bytes  | '-838:59:59' 到 '838:59:59' | HH:MM:SS | 时间值或持续时间 |
| YEAR |    1Byte   |  1901 到 2155  |   YYYY    |    年份值    |
| DATETIME |    8Bytes   | 1000-01-01 00:00:00 到 9999-12-31 23:59:59 | YYYY-MM-DD HH:MM:SS |  混合日期和时间值 |
| TIMESTAMP |  8Bytes  | 1970-01-01 00:00:00 到 2037 年某时 | YYYYMMDDhhmmss  | 混合日期和时间值，时间戳|

##### 优化建议
- MySQL能存储的最小时间粒度为秒。
- 建议用DATE数据类型来保存日期。MySQL中默认的日期格式是yyyy-mm-dd。
- 用MySQL的内建类型DATE、TIME、DATETIME来存储时间，而不是使用字符串。
- 当数据格式为TIMESTAMP和DATETIME时，可以用CURRENT_TIMESTAMP作为默认（MySQL5.6以后），MySQL会自动返回记录插入的确切时间。
- TIMESTAMP是UTC时间戳，与时区相关。
- DATETIME的存储格式是一个YYYYMMDD HH:MM:SS的整数，与时区无关，你存了什么，读出来就是什么。
- 除非有特殊需求，否则建议使用TIMESTAMP，它比DATETIME更节约空间。
- 有时人们把Unix的时间戳保存为整数值，但是这通常没有任何好处，这种格式处理起来不太方便，我们并不推荐它。

#### 字符串类型
| 类型 | 大小 | 用途 |
| --- | --- | --- |
| CHAR |   0-255字节 $(2^{8})$ | 定长字符串 |
| VARCHAR | 0-65535字节 $(2^{16})$ |  变长字符串 |
| TINYBLOB |    0-255字节 $(2^{8})$ | 不超过 255 个字符的二进制字符串 |
| TINYTEXT |    0-255字节 $(2^{8})$ | 短文本字符串 |
| BLOB |   0-65535字节 $(2^{16})$ |  二进制形式的长文本数据 |
| TEXT |   0-65535字节 $(2^{16})$ |  长文本数据 |
| MEDIUMBLOB | 0-16777215字节 $(2^{24})$|  二进制形式的中等长度文本数据 |
| MEDIUMTEXT | 0-16777215字节 $(2^{24})$ |  中等长度文本数据 |
| LONGBLOB |   0-4294967295字节 $(2^{32})$ |  二进制形式的极大文本数据 |
| LONGTEXT |   0-4294967295字节 $(2^{32})$ |  极大文本数据 |


##### 优化建议
- 字符串的长度相差较大用VARCHAR；字符串短，且所有值都接近一个长度用CHAR。
- CHAR和VARCHAR适用于包括人名、邮政编码、电话号码和不超过255个字符长度的任意字母数字组合。那些**要用来计算的数字不要用VARCHAR类型保存**，因为可能会导致一些与计算相关的问题。换句话说，**可能影响到计算的准确性和完整性**。
- BINARY和VARBINARY存储的是二进制字符串，与字符集无关。
- BLOB系列存储二进制字符串，与字符集无关。TEXT系列存储非二进制字符串，与字符集相关。一般情况下，你可以认为BLOB是一个更大的VARBINARY；TEXT是一个更大的VARCHAR。
- BLOB和TEXT都不能有默认值。


#### CHAR与VARCHAR，TEXT的区别
1. `char(n)`和`varchar(n)`中括号中n代表字符的个数，并不代表字节个数，所以当使用了中文的时候(UTF8)意味着可以插入m个中文，但是实际会占用`m*3`个字节，`m∗3<=255`，`m∗3<=65535`。使用 utf8mb4的话插入m个中文,会占用`m*4`个字节,`m∗4<=255`，`m∗4<=65535`。
2. 同时char和varchar最大的区别就在于char不管实际value都会占用n个字符的空间，而varchar只会占用实际字符应该占用的字节空间L+1(L=0到255)或L+2(L>255)，并且实际字节空间L+1<=255,或者L+2<=65535.
3. 超过char和varchar的n设置后，字符串会被截断。
4. char的上限为255字节，varchar的上限65535字节，text的上限为65535字节。
5. char在存储的时候会截断尾部的空格，varchar和text不会。
6. varchar(M),M范围是0~65535.M的值以最大行大小(65535字节)为准.例如,如果使用UTF-8编码,一个字符占3个字节,那么M最大为21844。GBK占2字节

#### VARCHAR和TEXT、BlOB类型的区别
1. VARCHAR，BLOB和TEXT类型是**变长类型**，对于其存储需求取决于列值的实际长度(在前面的表格中用L表示)，而不是取决于类型的最大可能尺寸。例如，一个VARCHAR(10)列能保存最大长度为10个字符的一个字符串，实际的存储需要是字符串的长度 ，加上1个字节以记录字符串的长度。对于字符串’abcd’，L是4而存储要求是5个字节。

2. BLOB和TEXT类型需要1，2，3或4个字节来记录列值的长度，这取决于类型的最大可能长度。**VARCHAR需要定义大小，有65535字节的最大限制；TEXT则不需要。**如果你把一个超过列类型最大长度的值赋给一个BLOB或TEXT列，值被截断以适合它。

3. **一个BLOB是一个能保存可变数量的数据的二进制的大对象。**4个BLOB类型TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB仅仅在他们能保存值的最大长度方面有所不同。

4. **BLOB 可以储存图片,TEXT不行**，TEXT只能储存纯文本文件。4个TEXT类型TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT对应于4个BLOB类型，并且有同样的最大长度和存储需求。在BLOB和TEXT类型之间的唯一差别是对BLOB值的排序和比较以大小写敏感方式执行，而对TEXT值是大小写不敏感的。换句话说，**一个TEXT是一个大小写不敏感的BLOB。**

> 效率来说基本是char>varchar>text，但是如果使用的是Innodb引擎的话，推荐使用varchar代替char
> char和varchar可以有默认值，text不能指定默认值

##### 使用建议
1. **根据字符的长度来判断**，是考虑其长度的是否相近来确定选择char还是varchar，如何字段的长度基本都是一样或者其长度总是近似的可以选用char
2. **是从碎片角度进行考虑**
用可变长度的字符型数据时，数据库管理员要时不时的对碎片进行整理。如执行数据库导出导入作业，来消除碎片。
3. **即使使用Varchar数据类型，也不能够太过于慷慨！** 比如你只使用到90个字符，VARCHAR(100)与VARCHAR(200)真的相同吗?结果是否定的。虽然他们用来存储90个字符的数据，其存储空间相同。但是对于内存的消耗是不同的。



#### INT显示宽度
> 我们经常会使用命令来创建数据表，而且同时会指定一个长度，如下。但是，这里的长度并非是TINYINT类型存储的最大长度，而是**显示的最大长度**。

TINYINT(2)中2的作用就是，当需要在查询结果前填充0时，命令中加上ZEROFILL就可以实现，如：

`id TINYINT(2) UNSIGNED ZEROFILL`
这样，查询结果如果是5，那输出就是05。如果指定TINYINT(5)，那输出就是00005，其实实际存储的值还是5，而且存储的数据不会超过255，只是MySQL输出数据时在前面填充了0。换句话说，在MySQL命令中，字段的类型长度**TINYINT(2)、INT(11)不会影响数据的插入，只会在使用ZEROFILL时有用，让查询结果前填充0**


### 事务
#### 事务的ACID原则
- Atomicity 原子性
- Consistency 一致性
- Isolation 独立性
- Durability 持久性

#### 事务的并发问题
1. **脏读**：事务A读取了事务B更新的数据，然后事务B回滚了，那么A读到的是脏数据
2. **不可重复读**： 事务A多次读取同一数据，事务B在A多次读取的过程中对数据作了修改，导致A读取同一数据的结果不一致
3. **幻读**：A管理员将数据库中的成绩改为ABCDEF等级，B管理员此时插入一条具体的记录，导致A以为还有一条没改，就像发生了幻觉一样
4. 丢失更新：A事务撤销时，把已提交的B事务的数据覆盖掉
5. 覆盖更新：A事务提交时，把已提交的B事务的数据覆盖掉

> **不可重复读**和**幻读**容易混淆，前者侧重于修改，后者侧重于新增或删除。
解决**不可重复读**的问题只需**锁住满足需要的行**，解决**幻读**需要**锁表**

#### 事务隔离级别

| 事务隔离级别 | 脏读 | 不可重复读 | 幻读 |
| --- | --- | --- | --- |
| 读未提交（read-uncommitted）|是|是|是|
| 读已提交（read-committed） |否|是|是|
| 可重复读（repeatable-read）|否|否|是|
| 串行化（serializable）|否|否|否|

> mysql默认的事务隔离级别为**可重复读repeatable-read**
可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）
mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。

补充：
1. 事务隔离级别为读已提交（不可重复读）时，写数据只会锁住相应的行
2. 事务隔离级别为可重复读时，如果检索条件**有索引（包括主键索引）**的时候，默认加锁方式是**next-key锁**；如果检索条件**没有索引**，更新数据时会**锁住整张表**。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读。
3. 事务隔离级别为串行化时，读写数据都会锁住整张表
4. 隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。

**数据库实现事务隔离的方式，基本可以分为以下两种：**

- 一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。

- 另一种是不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot），并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（ＭultiVersion Concurrency Control，简称MVCC或MCC），也经常称为多版本数据库。

在MVCC并发控制中，读操作可以分成两类：**快照读 (snapshot read)**与**当前读 (current read)**。

- 快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。

- 当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 
  在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以MySQL InnoDB为例：

  - 快照读：简单的select操作，属于快照读，不加锁。(当然，也有例外，如手动上锁)
  
  - 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。

#### 锁机制
**按封锁类型分类：**（数据对象可以是表可以是记录）

- 排他锁(eXclusive Lock)：（又称写锁，X锁）
一句总结：**会阻塞其他事务读和写。**
若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他任何事务都不能再对加任何类型的锁，直到T释放A上的锁。这就保证了其他事务在T释放A上的锁之前不能再读取和修改A。（但是INNODB中的查询是可以的，因为默认普通查询不加锁）<br>
**用法**<br>
`SELECT ... FOR UPDATE;`<br>
在查询语句后面增加FOR UPDATE，Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。
- 共享锁（Share Lock）：（又称读取，S锁）
一句总结：**会阻塞其他事务修改表数据。**
若事务T对数据对象A加上S锁，则其他事务只能再对A加S锁，而不能X锁，直到T释放A上的锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。<br>
**用法**<br>
`SELECT ... LOCK IN SHARE MODE;`<br>
在查询语句后面增加LOCK IN SHARE MODE，Mysql会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。
- 意向锁：
意向锁是表级锁，其设计目的主要是为了在一个事务中揭示下一行将要被请求锁的类型。InnoDB中的两个表锁：
    - 意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁
    - 意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。
**意向锁是InnoDB自动加的，不需要用户干预。**

> X锁和S锁都是加载某一个数据对象上的。也就是数据的粒度。

**按封锁的数据粒度分类**如下：
* 行级锁定（row-level）：
一句总结：**行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。**

**详细：**行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。

**缺陷：**由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。

* 表级锁定（table-level）：
一句总结：**表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。**

**详细：**和行级锁定相反，表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。

**缺陷：**锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并发度大打折扣。


* 页级锁定（page-level）：（MySQL特有）

一句总结：**页级锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般**。

**详细：**页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。

**缺陷：**页级锁定和行级锁定一样，会发生死锁。

从这里我们应该引申去思考行锁更多的缺点：（因为我们执行sql主要依赖行锁来提高并发度）
1. 比表级锁、页级锁消耗更多内存
2. 如果你在大部分数据上经常进行GROUP BY操作或者必须经常扫描整个表，比其它锁定明显慢很多。
3. 更容易发生死锁。

**表级锁与行级锁的优缺**
- 表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；
- 行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。

**理论上的事务的三级封锁协议：**
1. 一级封锁协议：事务T中如果对数据R有写操作，必须在这个事务中对R的第一次读操作前对它加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。
    > 一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。使用一级封锁协议可以**解决丢失修改问题**。
    在一级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，它**不能保证可重复读和不读“脏”数据**。

2. 二级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，**读完后方可释放S锁。**
   
    > 二级封锁协议除防止了丢失修改，还可以进一步防止读“脏”数据。但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读
    
3. 三级封锁协议 ：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，**直到事务结束才释放。**
   
    > 三级封锁协议除**防止了丢失修改**和**不读“脏”数据**外，还进一步**防止了不可重复读**。

三级锁操作一个比一个厉害（满足高级锁则一定满足低级锁）。但有个非常致命的地方，一级锁协议就要在第一次读加x锁，直到事务结束。几乎就要在整个事务加写锁了，效率非常低。三级封锁协议只是一个理论上的东西，实际数据库常用另一套方法来解决事务并发问题。

- 乐观锁
    乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。<br>
    通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。
- 悲观锁
    悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中的synchronized很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。
    - 共享锁
    - 排他锁
        - 记录锁（行锁）
        - 间隙锁
        - next-key锁（包含了记录锁和间隙锁）

##### MySQL的锁机制
###### MyISAM引擎
MyISAM只支持表级锁。表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。 
- 对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；
- MyISAM表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。

**如何加表级锁？**
MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作 （UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用LOCK TABLE命令给MyISAM表显式加锁。

```SQL
Lock tables orders read local, order_detail read local;
Select sum(total) from orders;
Select sum(subtotal) from order_detail;
Unlock tables;
```

**要特别说明以下两点内容：** 
1. 上面的例子在LOCK TABLES时加了“local”选项，其作用就是在**满足MyISAM表并发插入条件的情况下，允许其他用户在表尾并发插入记录**
2. 在用LOCK TABLES给表**显式加表锁时，必须同时取得所有涉及到表的锁**，并且**MySQL不支持锁升级**。也就是说，在执行LOCK TABLES后，**只能访问显式加锁的这些表，不能访问未加锁的表**；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。其实，在自动加锁的情况下也基本如此，**MyISAM总是一次获得SQL语句所需要的全部锁**。这也正是MyISAM表不会出现死锁（Deadlock Free）的原因。

当使用LOCK TABLES时，不仅需要一次锁定用到的所有表，而且，同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁定多少次，否则也会出错！举例说明如下。
```sql
mysql> lock table actor as a read,actor as b read;
```

**并发插入（Concurrent Inserts）**
    上文提到过MyISAM表的读和写是串行的，但这是就总体而言的。在一定条件下，MyISAM表也支持查询和插入操作的并发进行。 
MyISAM存储引擎有一个系统变量`concurrent_insert`，专门用以控制其并发插入的行为，其值分别可以为0、1或2。

- 当concurrent_insert设置为0时，**不允许并发插入**。
- 当concurrent_insert设置为1时，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。这也是**MySQL的默认设置**。
- 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。

> 可以利用MyISAM存储引擎的并发插入特性，来解决应 用中对同一表查询和插入的锁争用。例如，将concurrent_insert系统变量设为2，总是允许并发插入；同时，通过定期在系统空闲时段执行 OPTIMIZE TABLE语句来整理空间碎片，收回因删除记录而产生的中间空洞。

**MyISAM的锁调度**
MyISAM存储引擎的读锁和写锁是互斥的，读写操作是串行的。那么，一个进程请求某个 MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？答案是**写进程先获得锁**。不仅如此，**即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前**。这是因为MySQL认为写请求一般比读请求要重要。这也正是MyISAM表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。

我们可以通过一些设置来调节MyISAM的调度行为：
- 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。
- 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。
- 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。

另外，MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。
**tips**

> 一些需要长时间运行的查询操作，也会使写进程“饿死”！因此，应用中**应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题**，因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下**可以通过使用中间表等措施对SQL语句做一定的“分解”，使每 一步查询都能在较短时间完成，从而减少锁冲突**。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。

###### InnoDB引擎
InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。
**获取InonoD行锁争用情况**
可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：
```sql
mysql> show status like 'innodb_row_lock%';
```
![](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15535370706932.jpg)
如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，还可以通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。

**InnoDB的行锁模式及加锁方法**
InnoDB实现了以下两种类型的行锁。

- 共享锁（S）：又称读锁。允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。
- 排他锁（Ｘ）：又称写锁。允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。

对于共享锁大家可能很好理解，就是**多个事务只能读数据不能改数据**。 
对于排他锁大家的理解可能就有些差别，我当初就犯了一个错误，以为排他锁锁住一行数据后，其他事务就不能读取和修改该行数据，其实不是这样的。**排他锁指的是一个事务在一行数据加上排他锁后，其他事务不能再在其上加其他的锁**。mysql InnoDB引擎默认的修改数据语句：update,delete,insert都会自动给涉及到的数据加上排他锁，**select语句默认不会加任何锁类型**，如果加排他锁可以使用select …for update语句，加共享锁可以使用select … lock in share mode语句。**所以加过排他锁的数据行在其他事务中是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制。**

另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。

- 意向共享锁（IS）：事务打算给数据行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（IX）：事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

![](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15535372731710.jpg)

如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。 
**意向锁是InnoDB自动加的，不需用户干预**。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通SELECT语句，InnoDB不会加任何锁。 
事务可以通过以下语句显式给记录集加共享锁或排他锁：

- 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
- 排他锁（X）：SELECT * FROM table_name WHERE ... FOR UPDATE。
用SELECT ... IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，**对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁**。

**InnoDB行锁实现方式:**
**InnoDB行锁是通过给索引上的索引项加锁来实现的**。这一点MySQL与Oracle不同，后者是通过**在数据块中对相应数据行加锁**来实现的。InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁**！ 
在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。
- 在不通过索引条件查询的时候，InnoDB确实使用的是表锁，而不是行锁。
- 由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是**访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的**。
- **当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行**，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。 
- **即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的**，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突 时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。 

**间隙锁（Next-Key锁）**
> 当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

如：
```sql
Select * from  emp where empid > 100 for update;
```
是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。
InnoDB使用间隙锁的目的：
- 一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；
- 另外一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对锁机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况，在后续的章节中会做进一步介绍。

很显然，**在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待**。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要**尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件**。
还要特别说明的是，InnoDB除了通过范围条件加锁时使用间隙锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁

#### 小结
**对于MyISAM的表锁，主要讨论了以下几点：** 

1. 共享读锁（S）之间是兼容的，但共享读锁（S）与排他写锁（X）之间，以及排他写锁（X）之间是互斥的，也就是说读和写是串行的。 
2. 在一定条件下，MyISAM允许查询和插入并发执行，我们可以利用这一点来解决应用中对同一表查询和插入的锁争用问题。 
3. MyISAM默认的锁调度机制是写优先，这并不一定适合所有应用，用户可以通过设置LOW_PRIORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定LOW_PRIORITY选项来调节读写锁的争用。 
4. 由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，MyISAM表可能会出现严重的锁等待，可以考虑采用InnoDB表来减少锁冲突。

**对于InnoDB表，本文主要讨论了以下几项内容：**
1. InnoDB的行锁是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。 
2. 介绍了InnoDB间隙锁（Next-key)机制，以及InnoDB使用间隙锁的原因。 
在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。

在了解InnoDB锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括：
- 尽量使用较低的隔离级别；
- 精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会；
- 选择合理的事务大小，小事务发生锁冲突的几率也更小；
- 给记录集显式加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁；
- 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会；
- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响； 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁；
- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。

### 索引与性能分析
#### 索引建立的要求：

- **在关键字上建索引**
- **每张表的索引控制在5个以内，合理使用部分和联合索引**
- **不在结果集单一的列上建索引**
- **索引字段的结果集最好均匀分布，或者符合正态分布**
- **不对值过大的字段建索引**
- **join对称建立索引**，例如：A表的ID建立了索引，那么B表的PID也应该建立索引
- **组合索引（联合索引）的顺序最好一致**
-  使用**短索引**
- **不要索引包含有NULL值的列。** 只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。

#### 通过explain进行性能分析

##### EXPLAIN

**借助explain可以知道：**

- 什么时候必须为表加索引，以得到一个使用索引找到记录的更快的select方法
- 优化器是否以一个最佳次序联接表

##### EXPLAIN各属性分析
- **id**:查询的序列号
- **select_type**:查询的类型，主要包括普通查询，联合查询和子查询。
- **table**：表名
- **type**:联合查询使用的类型。结果值从好到坏一次是
     1. **system**(系统表)
     2. **const**(读常量)
     3. **eq_ref**(最多一条匹配结果，通常是主键访问)
     4. **ref**(被驱动表索引引用)
     5. **fulltext**（全文索引检索）
     6. **ref_or_null**(带空值的索引查询)
     7. **index_merge**(合并索引结果集)
     8. **unique_subquery**(子查询中返回的字段是唯一组合或索引)
     11. **index_subquery**(子查询返回的是索引，但非主键)
     12. **range**（索引范围扫描）
     13. **index**(全索引扫描)
     14. **ALL**（全表扫描）
- **possible_keys**:指出MySql可能**使用哪个索引在该表中找到该行**。如果为NULL则说明没有用到索引。这时要提高性能，可通过检验WHERE子句，看**是否引用了某些字段**，或者检查字段**是否适合索引**
- **key**:显示MySQL实际决定使用的键，没有被使用则为NULL
- **key_len**:显示MySQL决定使用的键的长度，如果key为NULL，则长度就是NULL
- **ref**:显示哪个字段或常数与key一起被使用
- **rows**:表示MySQL要遍历多少数据才能找到所需结果集，其在InnoDb上是不准确的
- **Extra**:
    - **Only Index**: 意味着信息只能用索引树中的信息检索，这比整表查要快
    - **where used**: 则表示使用了where限制，但是用索引还不够
    - **impossible where**: 则表示通过收集到的统计信息判断出不可能存在的结果
    - Using index: 用到了索引
    - Using filesort: 表示包含orderby且无法使用索引进行排序操作时，不得不使用相应的排序算法实现
    - using temporary: 使用临时表，常见于orderby和group by
    - Backward index scan 降序排序索引（MySQL8.0以上支持）
    - select tables optimized way: 使用聚合函数，并且MySQL进行了快速定位。通常是MAX,MIN,COUNT(*)等函数

> 一般来说，保证查询至少达到range级，最好能达到ref级。ALL为全表扫描，是最坏的情况，往往是因为没用到索引

#### 索引
> 索引分为**聚簇索引**和**非聚簇索引**两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。

##### 索引的选择性（Selectivity）
不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：Index Selectivity = Cardinality / #T 
显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。
**比值很小 代表 表中的记录大多数都是重复的**
##### B+树和Hash索引区别
Hash索引结构的特殊性，其检索效率非常高，**索引的检索可以一次定位**，不像B-Tree索引需要从根节点到枝节点，最后才能访问到叶节点**这样多次的IO访问**，所以 **Hash索引的查询效率要远高于B-Tree索引** 
###### Hash索引的缺点
- **Hash 索引仅仅能满足”=”,”IN”和”<=>”查询，不能使用范围查询。**
    由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
- **Hash 索引无法被用来避免数据的排序操作。**
    由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
- **Hash 索引不能利用部分索引键查询。**
    对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
- **Hash 索引在任何时候都不能避免表扫描。**
    Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。
- **Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。**
    对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息与同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下。

##### 聚簇索引（聚集索引）与非聚簇索引
###### 聚簇索引和非聚簇索引的区别
- **聚簇索引**的叶子节点就是**数据节点**，而**非聚簇索引**的叶子节点仍然是**索引节点**，只不过有指向对应数据块的指针。
- **聚簇索引主键的插入速度要比非聚簇索引主键的插入速度慢很多**。
- 相比之下，**聚簇索引适合排序**，非聚簇索引不适合用在排序的场合。因为**聚簇索引本身已经是按照物理顺序放置的**，排序很快。**非聚簇索引则没有按序存放，需要额外消耗资源来排序**。

MySQL InnoDB一定会建立聚簇索引，把实际数据行和相关的键值保存在一块，这也决定了一个表只能有一个聚簇索引，即MySQL不会一次把数据行保存在二个地方。MyISAM没有聚簇索引。
- 非聚簇索引
    ![](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15534272999675.jpg)
    非聚簇索引的主键索引和二级索引是没有什么区别的
- 聚簇索引(clustered index)
    1. 有主键时，根据主键创建聚簇索引
    2. 没有主键时，会用一个唯一且不为空的索引列做为主键，成为此表的聚簇索引
    3. 如果以上两个都不满足那innodb自己创建一个虚拟的聚集索引
    

![](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15534272135689.jpg)


- 辅助索引(secondary index)
    - InnoDB中非聚簇索引都是辅助索引（也叫二级索引），像复合索引、前缀索引、唯一索引
    - **在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。**辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。
        ![](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15534272365520.jpg)


###### 聚簇索引的优点
- **提高数据访问性能** 聚簇索引把索引和数据都保存到同一棵B+树数据结构中，并且同时将索引列与相关数据行保存在一起。这意味着，当你访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问，不必访问磁盘。MyISAM的数据是存放在磁盘的

###### 聚簇索引的缺点
- **维护索引很昂贵**，特别是插入新行或者主键被更新导致要分页(page split)的时候。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片
- 表如果使用UUID作为主键，会使数据存储稀疏，这就会出现聚簇索引有可能有比全表扫面更慢，所以**建议使用int的auto_increment作为主键** 
- **如果主键比较大的话，那辅助索引将会变的更大**，因为辅助索引的叶子存储的是主键值；过长的主键值，会导致叶子节点占用更多的物理空间

##### 索引类型
###### 主键和唯一索引区别
1. 主键是主键约束+唯一索引
2. 主键一定包含一个唯一索引，但唯一索引不是主键
3. 唯一索引列允许空值，但主键列不允许空值
4. 一个表只能有一个主键，但可以有多个唯一索引

###### FULLTEXT索引
仅可用于 MyISAM 表；对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法。
###### 单列索引、多列索引
**多个单列索引与单个多列索引的查询效果不同**，因为执行查询时，MySQL只能使用一个索引，会从多个索引中选择一个限制最为严格的索引。

###### 组合索引（联合索引）
**最左前缀**（带头索引不能死，中间索引不能断）。从前往后依次使用生效，如果中间某个索引没有使用，那么断点前面的索引部分起作用，断点后面的索引没有起作用；与书写顺序没有关系，如(a,b,c)组合索引，`a=1 and b=2`与`b=2 and a=1`等效，但`a=1 order by b asc`可以触发索引，`b=2 order by a`不行，mysql8.0以后，在多个字段排序不一致时，可以触发Backward index scan，之前的版本则不会触发索引
###### 前缀索引
对于Mysql中的字符列，我们可以选择在某些列上建立前缀索引。因为有些时候，**索引列很长，这会使得索引变得大且慢**，通常这时候，我们可以**索引该字符列开始的部分字符**，这样可以大幅**节约索引空间**，**提高索引效率**，但是需要注意的是，这样也可能会降低索引的选择性。因此，前缀索引的目标应该是：**要选择足够长的前缀以保证高的选择性，同时前缀不要太长**（以节约空间）
###### 覆盖索引
InnoDB支持覆盖索引（覆盖索引并非是一种可以通过SQL语句创建的索引，与前缀索引、联合索引不同，我们可以认为这是一种逻辑上的索引，即符合一定条件的索引我们都可以称之为是覆盖索引），即**从辅助索引中就可以直接得到查询的记录，而不需要再次查询聚集索引中的记录**。使用覆盖索引的一个好处就是**辅助索引不包含整行记录，因此它的大小远小于聚集索引，可以减少大量IO操作，查询速度很快**。
##### 索引失效的原因
- 在索引上进行其他操作(计算、函数、自动/手动类型转换等)
- 索引中范围条件（bettween、<、>、>=、<=等）右边的列,(in 在组合索引中不会失效)[mysql5.5]
- 索引中范围条件（<、>等）右边的列会失效,between，in，>=,<=不会失效)[mysql8.0或5.6以后，不确定]
- 索引字段上使用（!= 或者 <>,not in,is not null）判断时会失效[mysql5.5]
- 索引字段上使用（!= 或者 <>,not in,is not null）判断时不会失效，但会导致之后（右边）的索引失效。Extra里为Using index condition[mysql5.6新增]
- 索引字段使用like以通配符开头（‘%字符串’）时
- like以通配符结束相当于范围查找(‘字符串%’），索引不会失效。与范围条件（<、>等）不同的是：不会导致右边的索引失效。
- 索引字段是字符串，但查询时不加单引号，会导致索引失效而转向全表扫描
- 索引列含空值
- 如果MySQL估计使用索引比全表扫描更慢，则不使用索引
- 用or分割开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。
- 在JOIN操作中（需要从多个数据表提取数据时），MYSQL只有在主键和外键的数据类型相同时才能使用索引，否则即使建立了 索引也不会使用

优化总结：
![](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15534380097700.jpg)





### MySQL三种引擎

|  | MyISAM | Memory | InnoDB |
| --- | --- | --- | --- |
| 用途 | 快读 | 内存数据 | 完整的事务支持 |
| 锁 | 全表锁定 | 全表锁定 | 多种隔离级别的行锁 |
| 持久性 | 基于表恢复 | 无磁盘I/O,无可持久性 | 基于日志恢复 |
| 事务特性 | 不支持 | 不支持 | 支持 |
| 支持索引类型 | Btree,FullText,Rtree | Hash,Btree | Hash/Btree |

> MyISAM注重性能，InnoDB注重事务。但是在高并发的情况下，InnoDB效率要高很多，因为是行级锁。在索引的时候，InnoDB不光缓存索引，还缓存数据，所以占的资源多，更耗内存。

#### 存储引擎的选择
- 采用MyISAM:
    - R/W > 100:1且update较少
    - 并发不高，不需要事务
    - 表数据量小
    - 硬件资源有限
- 采用InnoDB：
    - R/W < 100:1且update频繁
    - 并发高，表数据量超过千万
    - 对安全性和可用性要求高
- 采用Memory：
    - 有足够的内存
    - 对数据一致性要求不高
    - 需要定期归档数据
    
### MySQL服务器调整优化策略
- 关闭不必要的二进制日志和慢查询日志，仅在内存足够或开发调试时候打开
    `show variables like '%slow%'` 检查慢查询是否打开的语句
    `SHOW GLOBAL STATUS LIKE '%SLOW%'` 查看慢查询的条数
- 适度使用Query Cache
- 增加MySQL允许的最大连接数
- 对于MyISAM表适当增加key_buffer_size
- 对于InnoDB表注意innodb_buffer_pool_size参数
- 从表中删除大量行后，可运行OPTIMIZE TABLE TableName进行碎片整理

### MySQL瓶颈及应对措施
- 增加MySQL配置中buffer和Cache的值，增加服务器CPU数量和内存大小（硬件和服务器优化效果最显著）
- 使用第三方引擎或衍生版本，如Percona,MariaDB,TokuDB等，但这些基本都是针对InnoDB的
- 迁移到其他数据库，PostgreSQL，SqlServer，Oracle等（MySQL是线程模式的，这些是进程模式的，能够更好的应用CPU资源）
- 对数据库进行分区分表
- 使用nosql等辅助解决方案
- 使用中间件做数据拆分和分布式部署，典型有阿里的Cobar分布式中间件
- 使用数据库连接池技术（由于MySQL锁机制不完善，可缓解在高并发下的连接压力）

## 数据库设计
### 范式与反范式
数据库五大范式：
1. 对于表中的每一行，必须且仅仅有唯一的行值.在一行中的每一列仅有唯一的值并且具有原子性。（第一范式是通过把重复的组放到每个独立的表中，把这些表通过一对多关联联系起来这种方式来消除重复组的。） **即无重复列**。
2. 第二范式要求非主键列是主键的子集，**非主键列必须完全依赖整个主键**。主键必须有唯一性的元素,一个主键可以由一个或更多的组成唯一值的列组成。一旦创建，主键无法改变，外键关联一个表的主键。主外键关联意味着一对多的关系。

    >（第二范式处理冗余数据的删除问题。当某张表中的信息依赖于该表中其它的不是主键部分的列的时候，通常会违反第二范式。）

3. 第三范式要求**非主键列互不依赖**。

    >（第三范式规则查找以消除没有直接依赖于第一范式和第二范式形成的表的主键的属性。我们为没有与表的主键关联的所有信息建立了一张新表。每张新表保存了来自源表的信息和它们所依赖的主键。） 

4. 第四范式 **禁止主键列和非主键列一对多关系不受约束**。
5. 第五范式 **将表分割成尽可能小的块**，为了排除在表中所有的冗余。

**适当的降低范式，增加冗余，用空间来换时间是值得的**
**设计数据库时应遵循的原则：**
- 核心业务使用范式
- 弱一致性需求--反ACID
- 空间换时间，冗余换效率
- 避免不必要的冗余

### 数据库分区
> 就是把数据表的文件和索引分散存储在不同的物理文件中。分区类型有Range，List，Hash,Key，其中Range最常用。
通常按照时间字段分区，有的使用用户分区等

**分区的限制：**
- 主键或唯一索引必须包含分区字段，如PRIMARY KEY(id,created),但对InnoBD来说，大主键性能不好
- 很多时候，使用分区就不要使用主键，否则可能影响性能
- 只能通过int类型或返回int类型的表达式来分区，通常使用YEAR或TO_DAYS等函数
- 每个表最多1024个分区，过度使用会消耗大量系统内存
- 采用分区的表不支持外键
- 分区后，可能造成索引失效

### 数据库分表
> 分区是把一个逻辑表文件分成多个物理文件存储，分表是把原先一个表拆分成多个表，通常有垂直拆分和水平拆分两种。水平切分最常用

## SQL注入的防范
- 对于整型变量或字段，使用intval()函数把传入的参数转化为一个数值
- 对于字符型变量用addslashes()把所有" ' \ 空字符串等转为含有\的溢出字符，或使用PDO参数绑定
- 转义特殊字符，如%等
- 保护表结构等关键信息
- 做好数据备份，以防万一

# 缓存
## 缓存的更新策略
- FIFO ，空间不够的情况下，最先缓存的先被清理
- LFU 最少使用的先被清理，要求缓存有hit属性
- LRU 最近最少使用的先被清理，先清理离当前时间戳最远的元素

## Memcached使用与实践
**Memcached是一个多线程的缓存服务器程序**
Memcache常用方法：
```php 
bool Memcache::add(string $key,mixed $var [, int $flag[, int $expire]])
```
- $key:缓存数据的键，长度不超过250字节
- $var:缓存数据的值，最大为1M
- $flag: 是否使用ZLib压缩
- $expire:缓存有效期，默认0为永不过期

add,replace,set(add和replace的集合)，get,delete,flush(立即使缓存失效)，
getServerStatus获取服务器在线状态，
getStats(获取服务器统计信息)

### Memcached分布式解决方案
- 普通Hash分布
- 一致性Hash分布

## Redis使用与实践
### redis的优点：
- 支持丰富的数据类型，如String，List， Set， Sorted Set, Hash等
- 支持两种数据持久化方式： Snapshotting(快照）和Append-Only file（追加）
- 支持主从复制

### Key相关命令

| 命令 | 描述 |
| --- | --- |
| exits key | 测试指定难过的key是否存在 1存在 0不存在 |
| del key1 key2 …keyN | 删除给定key,返回删除数目，0表示给定key都不存在 |
| type key | 返回给定key的value类型，none表示不存在key，string为字符类型，list为列表类型，set为无序集合类型 |
| keys pattern | 返回匹配指定模式的所以key |
| Expire key seconds | 给定key的过期时间 |
| randomkey | 返回从当前数据库中随机选择的一个key,如果当前数据库是空的，返回空串 |
| rename oldkey newkey | 重命名key,如果newkey存在将被覆盖，1表示成功，0表示失败，失败可能是oldkey不存在或和newkey相同 |
| renamenx oldkey newkey | 同上，如果newkey存在返回失败 |
| ttl key | 返回设置过期时间key的剩余秒数，-1表示key不存在或者没有设置过期时间 |
| move key db-index | 将key从当前数据库移动到指定数据库，返回1成功，0表示key不存在或者已经在指定数据库中 |

### redis支持的数据类型
#### string类型
**string类型是二级制安全的**
支持的命令：
`set`,`setnx`,`get`,`getset`,`mget`,`mset`,`msetnx`,`incr`, `decr`, `incrby`, `decrby`

#### list类型
> list类型只key对应的value是一个双向链表结构，所以list类型提供链表支持的所有操作

支持的命令：
`lpush`,`rpush`,`llen`,`lrange`,`ltrim`,`lset`,`lrem`,`lpop`,`rpop`,`blpop`,`brpop`
#### set类型
> set类型是一种无序集合，在redis内部通过HashTable实现，查找和删除的时间复杂度为o(1),用来记录不能重复的数据

支持的命令：
`sadd`,`srem`,`spop`,`srandmember`,`smove`,`scard`,`sismember`,`sinter`,`sinterstore`,`sunion`,`sunionstore`,`sdiff`,`sdiffstore`,`smembers`
#### sorted set类型
> 与set类型，但是是有序集合。通过一个double类型的整数score进行排序。sorted set通过skiplist(跳跃表)和HashTable组合完成，skipList负责排序，HashTable负责保存数据

支持的命令：
`zadd`,`zrem`,`zincrby`,`zrank`,`zrevrank`,`zrange`,`zrangebyscore`,`zcount`,`zcard`,`zscore`,`zremrangebyrank`,`zremrangebyscore`
#### hash类型
> hash类型每个key对应一个HashTable，添加修改删除时间复杂度都是o(1).hash类型适合应用于存储对象
> 新建hash对象时，redis使用zipmap存储数据，zipmap并不是真正的HashTable，时间复杂度是o(n),当field或value超出一定限制时，会自动转换成真正的HashTable

支持的命令：
`hset`,`hget`,`hmget`,`hmset`,`hincrby`,`hexists`,`hdel`,`hlen`,`hkeys`,`hvals`,`hgetall`

### redis持久化
两种方式：**Snapshotting(快照）和Append-Only file（追加）**
#### 内存快照
redis每隔一段时间做一次内存快照，客户端有save和bgsave两种方式通知redis。
> 
- redis由单线程处理所以请求，使用save会阻塞其他客户端请求
- 内存快照是每次都把内存数据完整的写到磁盘，而不是增量写入数据

#### 日志追加（aof）
把增加、修改数据的命令通过write函数追加到文件尾部（默认是appendonly.aof），redis重启时读取该文件中的所有命令并执行，从而把数据写入内存中
> 可以通过fsync函数强制操作系统把缓存写入磁盘 `appendonly yes`,`appendfsync always`,`appendfsync everysec`

### redis主从同步
一共两个阶段：
第一阶段：
1. slave服务器主动连接到master服务器
2. slave服务器发送sync命令给master服务器请求同步
3. master服务器备份数据库到rdb文件
4. master服务器把rdb文件传输给slave服务器
5. slave服务器清空数据库数据，把rdb文件导入数据库中

第二阶段：
接下来master服务器把用户所有更改数据的操作，通过命令的形式转发给所有salve服务器，slave只需要执行master服务器发送来的命令就可以了
### redis应用实战
- 消息队列
- 替代文件存储session

### 深入了解redis内核
#### 内存淘汰
内存不足时的处理方法：
- 启用虚拟内存，将vm-enabled设置为yes
- 启用内存淘汰, 将maxmemory设置为大于0的整数

内存淘汰的三种算法：通过maxmemory-policy指定
- **随机淘汰算法**
- **LRU淘汰算法** 最近最少访问的先淘汰
- **TTL淘汰算法** 最快过期的先淘汰

#### 对象引用计数器
为了解决get与del的冲突问题
#### 自动关闭超时连接
当一个客户端长时间不做任何操作时，redis就主动关闭它
#### 清除过期数据
redis清理过期数据分为两个阶段进行。
1. 在定时器中进行（serverCron），每隔100毫秒做一次清理过期数据的动作
2. 在用户获取数据时进行

#### Redis和Memcached整体对比
Redis的作者Salvatore Sanfilippo曾经对这两种基于内存的数据存储系统进行过比较，总体来看还是比较客观的，现总结如下：
1. **性能对比：**由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。
2. **内存使用效率对比：**使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。
3. **Redis支持服务器端的数据操作：**Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。


## 高性能网站架构方案
### 如何优化网站响应时间
1. 减少http请求
    - 将多个图片合并成一个文件，通过css背景图片偏移技术呈现
    - 合并JavaScript和CSS样式文件
    - 利用浏览器的cache功能，避免重复下载相同文件
2. 动态内容静态化（将不常改动的页面生成静态文件，如新闻页）
3. 优化数据库
4. 使用负载均衡
    - HTTP重定向
    - 基于DNS的轮询解析
    - 反向代理服务器

![-w499](https://gitee.com/vikieq/my_pic/raw/master/uPic/2021/10/11/15523622325772.jpg)
       
    1. upstream是一个关键字属性，后面的myname为自定义名
    sever_name是域名
    2. 2个server即是两个tomcat服务器的地址，weight属性是负载均衡的分配方式
    3. location / 是拦截所有的请求，下面的proxy_pass跟的是自定义名字，一定要和upstrean后面的名字一样，即可通过location里的pxory_pass的名字指向upstream的后自定义的名字，从而找到配置的2个tomcat服务器。
    4. 比较需要注意的一点，在location里面的3个proxy_set_header 特别重要，这3个属性是获得客户端的真实IP，因为当nginx反向代理之后会改变真实的IP

5. 使用缓存
    - 把查询结果存储到PHP文件中，需要时直接include
    - 把查询结果存储到memcached中，需要时直接读取